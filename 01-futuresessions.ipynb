{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_futures.sessions import FuturesSession\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./all_url.txt\",'r') as f:\n",
    "    text = f.readlines()\n",
    "    text = [i.strip() for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = FuturesSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(session, url):\n",
    "    future = session.get(url,headers= {'User-Agent': 'Mozilla/5.0'})\n",
    "    return future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time,sys\n",
    "\n",
    "def print_progress(futures):\n",
    "\n",
    "    check_done = lambda x: x.done()\n",
    "    check_done = np.vectorize(check_done)\n",
    "\n",
    "    #basic percentage progress\n",
    "    while not check_done(futures).all():\n",
    "        time.sleep(1)\n",
    "        percent = check_done(futures).mean() * 100\n",
    "        sys.stdout.write(\"\\r%d%%\" % percent)\n",
    "        sys.stdout.flush()    \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#create session with 16 workers\n",
    "session = FuturesSession(max_workers=32)\n",
    "#make all of the requests\n",
    "futures =   np.array([make_request(session,url) for url in url_list]) \n",
    "print_progress(futures)\n",
    "print(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [future.result().text for future in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# save_r = [json.dumps(i) for i in results]\n",
    "# save_r = json.dumps(save_r)\n",
    "\n",
    "# with open(\"save_results.json\",\"w\") as f:\n",
    "#     f.write(save_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open(\"save_results.json\",\"r\") as f:\n",
    "#     result = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubereat_page = []\n",
    "\n",
    "page = test\n",
    "\n",
    "soup = BeautifulSoup(page, 'lxml')\n",
    "try:\n",
    "    name = soup.find(\"h1\").text.encode().decode(\"unicode-escape\")\n",
    "except:\n",
    "    name = None\n",
    "\n",
    "try:\n",
    "    address = soup.find('p').text\n",
    "except:\n",
    "    address = None\n",
    "\n",
    "try:\n",
    "    stars = soup.find(\"div\", class_=\"header-score-details-left-score\").text.strip()\n",
    "except:\n",
    "    stars = None\n",
    "\n",
    "try:\n",
    "    review_count = soup.find(\"span\", itemprop=\"reviewCount\").text.strip()\n",
    "except:\n",
    "    review_count = None\n",
    "\n",
    "try:\n",
    "    bookmarks = soup.find(\"div\", class_=\"header-bookmark-count js-header-bookmark-count\").text.strip()\n",
    "except:\n",
    "    bookmarks = None\n",
    "\n",
    "try:\n",
    "    district = soup.find(\"div\", class_=\"header-poi-district dot-separator\").text.strip()\n",
    "except:\n",
    "    district = None\n",
    "\n",
    "try:\n",
    "    price_range = soup.find(\"div\", itemprop=\"priceRange\").text.strip()\n",
    "except:\n",
    "    price_range = None\n",
    "\n",
    "try:\n",
    "    food_type = soup.find(\"div\", class_=\"header-poi-categories dot-separator\").text.strip()\n",
    "except:\n",
    "    food_type = None\n",
    "\n",
    "try:\n",
    "    emoji = soup.find(\"div\", class_=\"header-smile-section\").text.strip().split(\"\\n\\n\")\n",
    "except:\n",
    "    emoji = None\n",
    "\n",
    "try:\n",
    "    address_ch = soup.find(\"section\", class_=\"address-section\").find_all(\"div\", class_=\"content\")[0].find(\"a\").text.strip()\n",
    "except:\n",
    "    address_ch = None\n",
    "\n",
    "try:\n",
    "    address_en = soup.find(\"section\", class_=\"address-section\").find_all(\"div\", class_=\"content\")[1].find(\"a\").text.strip()\n",
    "except:\n",
    "    address_en = None\n",
    "\n",
    "try:\n",
    "    transport = soup.find(\"section\", class_=\"transport-section\").find(\"div\", class_=\"content js-text-wrapper\").text.strip()\n",
    "except:\n",
    "    transport = None\n",
    "\n",
    "try:\n",
    "    telephone = soup.find(\"section\", class_=\"telephone-section\").find(\"div\", class_=\"content\").text.strip()\n",
    "except:\n",
    "    telephone = None\n",
    "\n",
    "try:\n",
    "    introduction = soup.find(\"section\", class_=\"introduction-section\").find(\"div\", class_=\"content js-text-wrapper\").text.strip().replace(\"\\r\",\"\").replace(\"\\n\",\"\")\n",
    "except:\n",
    "    introduction = None\n",
    "\n",
    "try:\n",
    "    open_hours = soup.find(\"div\", class_=\"opening-hours-section js-normal-and-special-opening-hours-section\").text.replace(\"\\n\",\"\")\n",
    "except:\n",
    "    open_hours = None\n",
    "\n",
    "try:\n",
    "    payment = soup.find(\"div\", class_=\"comma-tags\").text.strip()\n",
    "except:\n",
    "    payment = None\n",
    "\n",
    "try:\n",
    "    review = [i.text.strip() for i in soup.find_all(\"div\", class_=\"text js-text\")]\n",
    "except:\n",
    "    review = None\n",
    "\n",
    "ubereat_page.append({\"Name\" : name,\n",
    "    \"Delivery\" : delivery,\n",
    "    \"Address\" : address,\n",
    "#     \"Review_count\" : review_count,\n",
    "#     \"Bookmarks\" : bookmarks,\n",
    "#     \"District\" : district,\n",
    "#     \"Price_range\" : price_range,\n",
    "#     \"Food_type\" : food_type,\n",
    "#     \"Emoji\" : emoji,\n",
    "#     \"Address_ch\" : address_ch,\n",
    "#     \"Address_en\" : address_en,\n",
    "#     \"Transport\" : transport,\n",
    "#     \"Telephone\" : telephone,\n",
    "#     \"Intro\" : introduction,\n",
    "#     \"Openhours\" : open_hours,\n",
    "#     \"Payment\" : payment,\n",
    "#     \"Review\" : review,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(ubereat_page)\n",
    "df.to_csv(\"ubereats.csv\", mode='w', header=True, index=False)\t\n",
    "print(ubereat_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
